# 1주차
- - -
## 강의 4
- 레코드 수가 수천만 단위를 넘어가는 데이터 크기는 수 GB ~ 수백GB정도가 될 수 있다.
- 이 정도의 데이터는 처리하는 데에 시간이 걸리게 되고 아무 생각없이 작성한 쿼리에 대해 응답하지 않는다. 
- 이러한 문제들이 발생하면 데이터 분산 / 인덱스 설정 등으로 해결할 수 있는데 중요한 점은 이러한 기본적인 부분을 바탕으로 ***문제가 발생하면 그 자리에서 생각하자*** 는 점이다.
- - -
## 강의 5

### 대규모 데이터의 어려운 점
- 메모리 내에서 계산할 수 없다.
  - 이로 인해 디스크에 있는 데이터를 검색하게 된다.
- 디스크는 상당히 느리므로 I/O에 시간이 걸린다. 
- 메모리는 디스크보다 10^5 ~ 10^6 배 이상 빠르다.

### 디스크는 왜 느린가
- 디스크는 물리적인 동작을 수반한다.
  - 이 물리적인 구조가 탐색 속도에 영향을 주며 아무리 개선해도 메모리보다 빠를 수 없다.
- 그렇다면 메모리는 왜 빠를까?
  - 물리적인 동작 없이 실제 데이터를 탐색하기에 오버헤드가 거의 없다.
  - 메모리는 1회 탐색 시에 마이크로초로 처리가 가능하지만 디스크는 밀리초가 걸릴 수 있다.

### OS 레벨에서 디스크 단점 개선
- OS는 연속된 데이터를 같은 위치에 쌓고 데이터를 읽을 때 4KB 정도씩 한번에 읽을 수 있다.
- 이 덕분에, 디스크의 회전횟수를 최소화할 수 있지만 결국 회전 1회당 밀리초 단위이므로 메모리와의 속도차를 피할 수는 없다.

### 전송속도, 버스의 속도차
- 디스크와 메모리는 탐색속도 뿐만 아니라 전송속도에서도 많은 차이가 있다.
- 메모리 디스크 모두 CPU와 버스로 연결되어 있다.
- 메모리는 CPU와 상당히 빠른 버스로 연결되어 있지만 디스크는 그렇지 않기에 데이터가 많아지면 많아질 수록 전송 속도의 격차가 점점 벌어질 수 있다.
  - ex) `hdparm`이라는 Linux 툴로 측정 가능
- SSD가 나오면서 탐색속도에 개선이 점점 되고는 있지만, 버스 속도가 병목이 되거나 그 밖의 구조에 의지하기에 메모리만큼의 속도는 나오지 않는다.

***개발자는 확장성을 고려하여 메모리와 디스크 속도차를 생각하고 애플리 케이션을 만들어야 한다. 이는 매우 본질적이면서도 어려운 부분이다.***

### Linux 단일 호스트의 부하
- 서버 한대로 처리가능한 부하를 여러 서버로 분산하는 것은 `분산`에 어울리지 않다.
- 단일 서버의 성능을 충분히 끌어낼 수 있는 것을 시작으로 복수 서버에서의 분산이 의미를 갖는다.

#### 부하 계측방법

1. **Load Average 확인**
    - Load Average 는 시스템 전체의 부하상황을 나타내는 지표이다. 
    - top 이나 uptime 등의 명령으로 Load Average 를 확인할 수 있다.
2. **CPU, I/O 중 병목 원인 조사**
    - Load Average 가 높은 경우, CPU 와 I/O 어느 쪽에 원인이 있는지를 조사한다.
    - sar 이나 vmstat 로 시간 경과에 따라 CPU 사용률이나 I/O 대기율의 추이를 확인할 수 있으므로 이를 참고하여 규명한다.

- 일반적으로 CPU에 부하가 걸리는 상황들이다.
  1. 프로그램의 폭주
      - 프로그램의 개선 / 메모리 증설 혹은 분산을 검토해볼 수 있다.
  2. 디스크 혹은 메모리 용량(트래픽 부하 등으로 인한) 등을 제외한 부분에서는 병목이 되지 않는 상황
      - 이는 서버 증설 혹은 프로그램의 로직 / 알고리즘의 개선으로 대응할 수 있다.

#### OS튜닝이란
- 부하를 계측했다면, 이제 OS 성능을 향상시키기 위한 튜닝을 할 수 있다.
- 본래 튜닝의 의미는 ***병목의 제거*** 작업과 같다. 즉, 문제가 될만한 부분을 제거하는 것이다.
- 예를 들면 I/O 성능을 개선하기 위해 이와 같은 작업들을 고려할 수 있다.
  - 메모리 증설을 통해 캐시 영역을 확보하여 대응할 수 있는가
  - 원래 데이터량이 너무 많지 않은가
  - 애플리케이션의 I/O 알고리즘을 변경할 필요가 있는가

***원인을 알면 대응방법은 자명하기에, 이를 실천하는 것이 `튜닝`인 것이다***
- - -
## 강의 6

### 규모조정, 확장성
- 대규모 환경이란, 여러 서버를 통해 부하를 분산하는 환경이라 해도 무방하다.
  - 웹 서비스에서는 서버자체의 스펙을 올리는 `scale-up`보다는 여러 개의 저스펙의 서버를 나열해 시스템 전체 성능을 올리는 `scale-out` 전략이 주류를 이룬다.
  - 10배의 과금이 발생하는 서버의 성능이 속도나 신뢰성 면에서 10배만큼 발휘하지 않기 때문이다.
- 시스템 구성의 유연성이란, 공통적으로 상황 대처가 쉽다는 점이다.
  - 부하가 적은 경우엔, 최소한의 투자로 부하가 높아짐에 따라 확장하기 쉽다는 점
  - 상당한 용도의 서버도 저렴하고 간단하게 준비할 수 있다는 점

`규모조정의 요소`
- `sclae-out`은 서버를 횡으로 전개해 확장성을 확보하게 되는데, 이 때 CPU 부하의 확장성을 확보하기는 쉽다.
  - ex) http요청을 받아 db로부터 받은 데이터를 클라이언트로 응답할 때는 기본적으로 cpu부하만 소요
- 하지만 DB측면에서는 I/O 부하만 걸린다.
  - 여러 DB를 두었을 때(ex) slave DB, master DB) 데이터에 변화가 생길 때, 동기화하는 부분에서 문제가 생길 수 있다. 이처럼 쓰기는 간단히 분산할 수가 없다.
  - 즉, 대규모 환경에서는 I/O 부하를 부담하고 있는 서버는 분산시키기 어렵고 디스크 I/O가 많이 발생하면 서버가 금새 느려지는 문제가 있다.

***이처럼 규모조정 요소에서 CPU부하 뿐만 아니라, I/O부하에 대해 생각해야 한다는 점을 확실히 파악해둬야 한다.***

`멀티태스킹 OS와 부하`
- Windows, Linux 등 멀티태스킹이 가능한 OS들은, 짧은 시간 간격으로 여러 태스크를 전환해가며 처리함으로써 멀티태스킹을 실현하고 있다.
- 실행할 태스크가 적으면 대기없이 전환이 가능하지만, 태스크가 늘어날 수록 수행 중인 특정 태스크가 존재하는 동안 나머지 태크스들은 CPU에 시간이 날 때까지 대기하게 된다. 이는 프로그램의 `실행지연`으로 나타나게 된다.
  - top의 출력내용에는 `Load Average`라는 수치가 포함되어 있는데, 평균적으로 어느 정도의 태스크가 대기상태로 있엇는지를 보고하는 수치다. 따라서, 이 수치가 높을만큼 부하가 높은 상황이라고 할 수 있다.
  - 하드웨어는 일정 주기로 CPU로 인터럽트 신호를 보낸다.(=타이머 인터럽트)
  - 이 일정 주기 동안 실행 중인 프로세스의 CPU사용량 등의 시간관련 처리를 수행한다.
  - 이 주기마다 Load Average 값이 계산된다.
  - 커널은 타이머 인터럽트가 발생했을 때 실행가능 태스크와 I/O 대기인 태스크의 실행개수를 세어둔다. 그 값을 단위 시간으로 나눈 것이 Load Average 값이라 할 수 있다.
    - (실행가능 태스크 = 다른 태스크가 CPU를 점유하고 있어 계산을 시작할 수 없는 태스크)
  - 즉, Load Average가 의미하는 부하는 이와 같은 의미를 갖고 있다.
    - 처리를 실행하려 해도 할 수 없어서 대기하고 있는 프로세스의 수
      - CPU의 실행권한이 부여되기를 기다리고 있는 프로세스
      - 디스크 I/O가 완료하기를 기다리고 있는 프로세스
  - 하지만, Load Average 값만으로는 CPU 부하가 높은지, I/O 부하가 높은지 판단할 수 없다.